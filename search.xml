<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title> CNN</title>
    <url>/2024/11/03/Deep-learning-Lhy-learning-CNN/</url>
    <content><![CDATA[<h2 id="概述">概述</h2>
<p>卷积神经网络（CNNs）是一类专门用于处理结构化网格数据（如图像）的神经网络。CNN通过局部连接性和参数共享来有效提取层次化的特征。 <span id="more"></span></p>
<hr>
<h2 id="神经元与感受野">1. 神经元与感受野</h2>
<h3 id="神经元功能的简化">1.1 神经元功能的简化</h3>
<ul>
<li>每个神经元专注于特定的<strong>感受野</strong>（Receptive Field），这种局部化特性使得神经网络可以检测局部特征，而不是处理整个图像。</li>
</ul>
<p>.</p>
<h3 id="典型的卷积层设置">1.2 典型的卷积层设置</h3>
<ul>
<li><p><strong>通道（Channels）</strong>：输入数据通常具有多个通道（例如 RGB 图像）。</p></li>
<li><p><strong>核大小（Kernel Size）</strong>：定义核（滤波器）的大小（例如 3x3），决定了神经元观察的图像范围。</p></li>
<li><p><strong>神经元重叠</strong>：多个神经元可以覆盖相同的感受野，提高检测准确度。</p></li>
<li><p><strong>步幅（Stride）</strong>：定义核如何在图像上移动，允许感受野的重叠。</p></li>
<li><p><strong>填充（Padding）</strong>：如零填充技术确保卷积操作可以在图像边缘应用。</p></li>
</ul>
<figure>
<img src="/2024/11/03/Deep-learning-Lhy-learning-CNN/image-1.png" alt="典型卷积层设置"><figcaption>典型卷积层设置</figcaption>
</figure>
<hr>
<h2 id="参数共享">2. 参数共享</h2>
<h3 id="参数共享的效率">2.1 参数共享的效率</h3>
<ul>
<li><strong>冗余神经元</strong>：相似的感受野中可以共享参数，而不是为每一个感受野分配不同的神经元，提升了效率。</li>
</ul>
<figure>
<img src="/2024/11/03/Deep-learning-Lhy-learning-CNN/image-2.png" alt="不同区域相似模式"><figcaption>不同区域相似模式</figcaption>
</figure>
<h3 id="共享机制">2.2 共享机制</h3>
<ul>
<li><p>拥有相同感受野的神经元不共享参数，允许专门化。</p></li>
<li><p>在不同位置观察相似模式的神经元可以共享参数，降低模型大小与复杂性。</p></li>
</ul>
<figure>
<img src="/2024/11/03/Deep-learning-Lhy-learning-CNN/image-3.png" alt="参数共享"><figcaption>参数共享</figcaption>
</figure>
<hr>
<h2 id="卷积层的优点">3. 卷积层的优点</h2>
<ul>
<li><p><strong>局部模式检测</strong>：许多图像中的模式都比整个图像小，卷积层可专注于局部特征。</p></li>
<li><p><strong>平移不变性</strong>：相同的模式可在图像不同部分出现，增强网络的泛化能力。</p></li>
<li><p><strong>降低过拟合</strong>：卷积层通常比全连接层参数更少，降低了过拟合的风险。</p></li>
<li><p><strong>图像专用</strong>：专为图像与视频数据设计，卷积层可以更有效地提取特征。</p></li>
</ul>
<figure>
<img src="/2024/11/03/Deep-learning-Lhy-learning-CNN/image-5.png" alt="卷积层的优点"><figcaption>卷积层的优点</figcaption>
</figure>
<hr>
<h2 id="池化层">4. 池化层</h2>
<h3 id="池化的目的">4.1 池化的目的</h3>
<ul>
<li>池化层减少特征图的维度，帮助保留重要特征，同时降低计算负担。</li>
</ul>
<h3 id="池化类型">4.2 池化类型</h3>
<ul>
<li><strong>最大池化（Max Pooling）</strong>：从定义的窗口中选择最大值，保留关键特征并缩小尺寸。</li>
</ul>
<figure>
<img src="/2024/11/03/Deep-learning-Lhy-learning-CNN/image-12.png" alt="池化"><figcaption>池化</figcaption>
</figure>
<hr>
<h2 id="cnn的结构">5. CNN的结构</h2>
<h3 id="架构">5.1 架构</h3>
<ul>
<li>一个典型的CNN由交替的卷积和池化层组成，最后是全连接层，根据提取的特征进行分类。</li>
</ul>
<figure>
<img src="/2024/11/03/Deep-learning-Lhy-learning-CNN/image-13.png" alt="完整的CNN"><figcaption>完整的CNN</figcaption>
</figure>
<hr>
<h2 id="滤波器与特征图">6. 滤波器与特征图</h2>
<h3 id="滤波器filters">6.1 滤波器（Filters）</h3>
<ul>
<li>滤波器是CNN的核心组件，每个滤波器设计用于检测局部区域中的特定模式（例如跨越所有通道的3x3像素区域）。</li>
</ul>
<figure>
<img src="/2024/11/03/Deep-learning-Lhy-learning-CNN/image-6.png" alt="滤波器"><figcaption>滤波器</figcaption>
</figure>
<h3 id="生成特征图">6.2 生成特征图</h3>
<ul>
<li>每个滤波器在输入图像上进行卷积，生成<strong>特征图</strong>，显示特定模式在图像中的分布。</li>
</ul>
<figure>
<img src="/2024/11/03/Deep-learning-Lhy-learning-CNN/image-8.png" alt="特征图"><figcaption>特征图</figcaption>
</figure>
<h3 id="层次特征学习">6.3 层次特征学习</h3>
<ul>
<li>随着网络加深，滤波器能够捕捉到更复杂的模式，使模型学习更高级的特征。</li>
</ul>
<figure>
<img src="/2024/11/03/Deep-learning-Lhy-learning-CNN/image-9.png" alt="更深层的特征"><figcaption>更深层的特征</figcaption>
</figure>
<hr>
<h2 id="神经元与滤波器功能的比较">7. 神经元与滤波器功能的比较</h2>
<ul>
<li>具有不同感受野且共享参数的神经元的工作方式类似于滤波器在输入图像上进行卷积，这种设计结合了参数共享与局部特征检测的优势。</li>
</ul>
<figure>
<img src="/2024/11/03/Deep-learning-Lhy-learning-CNN/image-10.png" alt="参数共享与滤波器卷积"><figcaption>参数共享与滤波器卷积</figcaption>
</figure>
<hr>
<h2 id="总结">8. 总结</h2>
<p>卷积神经网络（CNNs）是一种适用于图像处理的强大架构，利用局部化检测、参数共享和层次特征提取，在图像分类和物体检测等任务中表现优异。</p>
<figure>
<img src="/2024/11/03/Deep-learning-Lhy-learning-CNN/image-11.png" alt="比较表"><figcaption>比较表</figcaption>
</figure>
]]></content>
      <categories>
        <category>Deep-learning</category>
        <category>Lhy-learning</category>
      </categories>
      <tags>
        <tag>deep-learning-notes</tag>
      </tags>
  </entry>
  <entry>
    <title>Self Attention</title>
    <url>/2024/11/03/Deep-learning-Lhy-learning-Self-Attention/</url>
    <content><![CDATA[<h1 id="自注意力机制self-attention">自注意力机制（Self Attention）</h1>
<span id="more"></span>
<h2 id="输入的向量集">输入的向量集</h2>
<ul>
<li>One-hot 编码</li>
<li>词嵌入 (word embedding) ## 输出</li>
<li>每个向量对应一个标签（序列标注）</li>
<li>整个序列有一个标签</li>
<li>模型可以自行决定标签数量（seq2seq）</li>
</ul>
<h2 id="序列标注-sequence-labeling">序列标注 (Sequence Labeling)</h2>
<ul>
<li>可以考虑上下文信息</li>
<li>将整个序列放在一个窗口中计算可能会消耗大量资源</li>
</ul>
<h2 id="自注意力机制-self-attention">自注意力机制 (Self-attention)</h2>
<figure>
<img src="/2024/11/03/Deep-learning-Lhy-learning-Self-Attention/image-new.png" alt="自注意力机制"><figcaption>自注意力机制</figcaption>
</figure>
<ul>
<li>找到与 <span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.023ex;" xmlns="http://www.w3.org/2000/svg" width="2.185ex" height="1.909ex" role="img" focusable="false" viewbox="0 -833.9 965.6 843.9"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msup"><g data-mml-node="mi"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"/></g><g data-mml-node="mn" transform="translate(562,363) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"/></g></g></g></g></svg></mjx-container></span> 相关的向量，用 <span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.025ex;" xmlns="http://www.w3.org/2000/svg" width="1.448ex" height="1.025ex" role="img" focusable="false" viewbox="0 -442 640 453"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D6FC" d="M34 156Q34 270 120 356T309 442Q379 442 421 402T478 304Q484 275 485 237V208Q534 282 560 374Q564 388 566 390T582 393Q603 393 603 385Q603 376 594 346T558 261T497 161L486 147L487 123Q489 67 495 47T514 26Q528 28 540 37T557 60Q559 67 562 68T577 70Q597 70 597 62Q597 56 591 43Q579 19 556 5T512 -10H505Q438 -10 414 62L411 69L400 61Q390 53 370 41T325 18T267 -2T203 -11Q124 -11 79 39T34 156ZM208 26Q257 26 306 47T379 90L403 112Q401 255 396 290Q382 405 304 405Q235 405 183 332Q156 292 139 224T121 120Q121 71 146 49T208 26Z"/></g></g></g></svg></mjx-container></span> 表示相关向量 <img src="/2024/11/03/Deep-learning-Lhy-learning-Self-Attention/image-1-new.png" alt="相关向量"></li>
<li>使用点积 (Dot-product) 和加法 (Additive) 来计算 <img src="/2024/11/03/Deep-learning-Lhy-learning-Self-Attention/image-2-new.png" alt="计算方法"></li>
<li>也可以使用其他函数如 ReLU <img src="/2024/11/03/Deep-learning-Lhy-learning-Self-Attention/image-3-new.png" alt="处理过程"> <img src="/2024/11/03/Deep-learning-Lhy-learning-Self-Attention/image-4-new.png" alt="得到 b1"></li>
</ul>
<h3 id="矩阵描述">矩阵描述</h3>
<p><img src="/2024/11/03/Deep-learning-Lhy-learning-Self-Attention/image-5-new.png" alt="如何得到 q、k、v">[<img src="/2024/11/03/Deep-learning-Lhy-learning-Self-Attention/image-7-new.png" alt="得到注意力分数">![<img src="/2024/11/03/Deep-learning-Lhy-learning-Self-Attention/image-8-new.png" alt="得到 b">![<img src="/2024/11/03/Deep-learning-Lhy-learning-Self-Attention/image-9-new.png" alt="总结"></p>
]]></content>
      <categories>
        <category>Deep-learning</category>
        <category>Lhy-learning</category>
      </categories>
      <tags>
        <tag>deep-learning-notes</tag>
      </tags>
  </entry>
  <entry>
    <title>Lhy-HW3</title>
    <url>/2024/11/03/Deep-learning-Projects-Lhy-HW3/</url>
    <content><![CDATA[<h1 id="hw3">HW3</h1>
<p><span id="more"></span></p>
<h2 id="任务分析">任务分析</h2>
<ul>
<li><p>本次作业要求对food11进行分类</p></li>
<li><p>作业的分数细则如下：</p></li>
<li><p>Simple: 0.50099</p></li>
<li><p>Medium: 0.73207 - Training augmentation + longer training</p></li>
<li><p>Strong: 0.81872 - Training augmentation + model design + extended training (+ cross-validation + ensemble)</p></li>
<li><p>Boss: 0.88446 - Training augmentation + model design + test-time augmentation + extended training (+ cross-validation + ensemble)</p></li>
</ul>
<h2 id="完成细节">完成细节</h2>
<h3 id="模型">模型</h3>
<ul>
<li><p>resnet18，按照李沐动手学深度学习教程搭建。</p></li>
<li><p>resnet，用了两层残差块，然后接全连接层</p></li>
</ul>
<h3 id="训练设置">训练设置</h3>
<ul>
<li><p>resnet中采用StepLRScheduler，训练100 epochs，前50轮学习率为3e-4，后50轮为3e-5</p></li>
<li><p>resnet18采用余弦退火策略，200epochs，T_MAX设置为200，学习率按余弦从3e-4减小到3e-7</p></li>
<li><p>均采用5折交叉验证</p></li>
<li><p>resnet18只训练出四个模型</p></li>
<li><p>batch_size都设置为64</p></li>
<li><p>采用FocalLoss，根据resnet对各个类别的分类情况调整了alpha系数</p></li>
</ul>
<h2 id="结果">结果</h2>
<ul>
<li><p>resnet达到了StrongLine</p></li>
<li><p>resnet18达到了BossLine</p></li>
</ul>
<p><img src="/2024/11/03/Deep-learning-Projects-Lhy-HW3/image.png"></p>
<p><a href="https://github.com/HouxiongYao/Deep-Learning-Projects">完整代码在这里</a></p>
]]></content>
      <categories>
        <category>Deep-learning</category>
        <category>Projects</category>
      </categories>
      <tags>
        <tag>Lhy-Projects</tag>
      </tags>
  </entry>
</search>
